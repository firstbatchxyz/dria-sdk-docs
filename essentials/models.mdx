---
title: 'Models'
description: 'Understanding and selecting models in Dria'
---

## Available Models in Dria

Dria provides access to a variety of language models that can be used for different tasks in your workflows and pipelines. The available models range from smaller, faster models to larger, more powerful ones.

## Model Selection

You can select specific models for different steps in your workflows using the `ModelSelector` class:

```python
from dria.models import ModelSelector
from dria_workflows import *

builder = WorkflowBuilder(instruction="Analyze scientific text")

builder.generative_step(
    id="analyze_text",
    prompt="Provide a detailed analysis of this scientific concept: {{instruction}}",
    operator=Operator.GENERATION,
    model=ModelSelector.claude_3_opus(),  # Specify a powerful model
    outputs=[Write.new("analysis")],
)
```

## Model Categories

### Claude Models

Claude models from Anthropic are known for their strong reasoning capabilities and ability to follow complex instructions.

| Model | Description | Best For |
| ----- | ----------- | -------- |
| `claude_3_opus()` | Most powerful Claude model | Complex reasoning, creative content, detailed analysis |
| `claude_3_sonnet()` | Balanced performance and speed | General-purpose tasks, content generation |
| `claude_3_haiku()` | Fastest Claude model | Quick responses, simple tasks, high throughput |

### GPT Models

OpenAI's GPT models offer strong performance across a wide range of tasks.

| Model | Description | Best For |
| ----- | ----------- | -------- |
| `gpt_4()` | Most powerful GPT model | Complex reasoning, creative content |
| `gpt_4_turbo()` | Optimized for speed and performance | Balanced performance and efficiency |
| `gpt_3_5_turbo()` | Fast and efficient | Simple tasks, high throughput |

### Llama Models

Meta's Llama models provide open-source alternatives with strong performance.

| Model | Description | Best For |
| ----- | ----------- | -------- |
| `llama_3_70b()` | Largest Llama 3 model | Complex reasoning, detailed responses |
| `llama_3_8b()` | Smaller Llama 3 model | Efficient processing, simpler tasks |

## Choosing the Right Model

When selecting a model for your workflow, consider:

1. **Task Complexity**: More complex tasks benefit from more powerful models
2. **Speed Requirements**: Faster models are better for high-throughput applications
3. **Cost Efficiency**: Smaller models are generally more cost-effective
4. **Specific Strengths**: Some models excel at particular tasks

## Model Selection Strategy

A common strategy is to use different models for different steps in your workflow:

```python
from dria.models import ModelSelector
from dria_workflows import *

builder = WorkflowBuilder(instruction="Generate and summarize content")

# Use a powerful model for complex content generation
builder.generative_step(
    id="generate_content",
    prompt="Write a detailed technical article about {{instruction}}",
    operator=Operator.GENERATION,
    model=ModelSelector.claude_3_opus(),
    outputs=[Write.new("content")],
)

# Use a faster model for summarization
builder.generative_step(
    id="summarize_content",
    prompt="Summarize this article in 3 bullet points: {{content}}",
    operator=Operator.GENERATION,
    model=ModelSelector.claude_3_haiku(),
    outputs=[Write.new("summary")],
)

flow = [
    Edge(source="generate_content", target="summarize_content"),
    Edge(source="summarize_content", target="_end")
]

builder.flow(flow)
```

## Model Parameters

You can customize model behavior by adjusting parameters:

```python
from dria.models import ModelSelector, ModelParameters
from dria_workflows import *

# Create custom model parameters
params = ModelParameters(
    temperature=0.7,  # Controls randomness (0.0 to 1.0)
    top_p=0.9,        # Controls diversity
    max_tokens=1000   # Maximum response length
)

# Apply parameters to a model
model = ModelSelector.claude_3_sonnet().with_parameters(params)

# Use in a workflow
builder = WorkflowBuilder(instruction="Generate creative content")
builder.generative_step(
    id="generate_creative",
    prompt="Write a creative story about {{instruction}}",
    operator=Operator.GENERATION,
    model=model,
    outputs=[Write.new("story")],
)
```

### Common Parameters

| Parameter | Description | Typical Range |
| --------- | ----------- | ------------- |
| `temperature` | Controls randomness | 0.0 (deterministic) to 1.0 (creative) |
| `top_p` | Controls diversity | 0.0 to 1.0 (higher = more diverse) |
| `max_tokens` | Maximum response length | Depends on model limits |
| `stop_sequences` | Sequences that stop generation | Model-specific |

## Best Practices

1. **Match Model to Task**: Use powerful models for complex tasks and faster models for simpler tasks
2. **Test Different Models**: Experiment with different models to find the best fit for your specific use case
3. **Optimize Parameters**: Adjust temperature and other parameters to control output quality and diversity
4. **Consider Fallbacks**: Implement fallback strategies if a preferred model is unavailable
5. **Monitor Performance**: Track model performance and adjust your strategy as needed

## Next Steps

Now that you understand model selection in Dria, you can:

<CardGroup cols={2}>
  <Card
    title="Data Generation"
    icon="database"
    href="/essentials/data-generation"
  >
    Learn techniques for generating high-quality synthetic data
  </Card>
  <Card
    title="Structured Outputs"
    icon="code"
    href="/essentials/structured-outputs"
  >
    Discover how to generate data in specific formats
  </Card>
</CardGroup> 